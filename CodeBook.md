Code book for making the wearable computing data tidy
=====================================================

Please refer to README.md for the complete description of the goal of this project. Next are the different steps taken to retrieve the data set and make it tidy.

this project is expected to provide 2 data sets, both created by the run_analysis.R script. The scripts provides 2 results:
1. the variable "dataset_data" contains the data we're interested in (items 1 to 4 described in README.md)
2. the variable "dataset_tidy" contains the tidy data set as specified by item 5 in README.md

Please notice that background information about the data used here can be found at the following location: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones. The most relevant information for understanding the data set are also available in the dataset_and_attributes_info.md file in this project.

This document contains information regarding the logic related to the data processing. Implementation details are documented in the run_analysis.R script.

1. download the original data set from: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip*
2. unzip the data set. The data set is unzipped in the "UCI HAR Dataset". in that folder, there is a README.txt and a feature_info.txt file describing the full data set in details.
3. load the data set in memory. We don't have to include the inertial signals, so we have to load the 6 following files: X_train.txt, y_train.txt, subject_train.txt, X_test.txt, y_test.txt and subject_test.txt. The data sets are loaded in the following variables: X_train, y_train, subject_train, X_test, y_test and subject_test. We'll also need the names of the different features  and activities later, so we also load "features.txt" in the variable "featureNames" and "activity_labels.txt" in the variable "activityLabels".
4. merge the training and test sets. The 6 variables X_train, y_train, subject_train, X_test, y_test and subject_test from step 3 are merged into a single data set, stored in the variable "merged". y and subject are considered as 2 additional columns while the test and training set rows all contain different samples (= new rows). "subject" is added as first column while "y" is added as last column.
5. extract only the measurements on the mean and standard deviation for each measurement. In other words, we are here filtering the data set so that we only keep the features which are either means or standard deviations. We can see in feature_info.txt that those feature contain "mean()", "meanFreq()"" and "std()" in their names. So only those will be kept. In https://class.coursera.org/getdata-007/forum/thread?thread_id=49, there is a discussion whether we should only consider those features whose names end with these strings or all those whose names include that string. I consider that we should here include all means and standard deviations, regardless of the position of the "mean()" or "std()" strings. I also consider that the "meanFreq" string is a mean, since it's giving a mean frequency as per its description in "features_info.txt". However, I don't consider the angles variables such as angle(Z,gravityMean) as means since their main prupose is to give angles. So, to summarize, I keep in the data set the columns whose names contain either "mean()", "meanFreq()" or "std()". I also keep the last column, which correspond to the initial y files, since they will be needed for the next step. The resulting dataset is kept in the "dataset_data" variable.
6. Uses descriptive activity names to name the activities in the data set. Here we replace the different numbers in the last column of the data set by the activity labels. The mapping between the numbers in the last column of "merged" and the labels is described in the "activity_labels.txt" file.
7. Appropriately labels the data set with descriptive variable names. The different columns of the data set are named according to the content of the featureNames variable. That variable contains the index of the "merged" column in the first column and the name of the "merged" column in the second column. It's important to remember that the data set columns were filtered at step 5, and so the "featureNames" variable has to be filtered as well. The last column of the merged data set contains the activities and so, it is named "activities". After that step, the "dataset_data" is in the shape expected for the project.
8. From the data set "dataset_data", creates a second, independent tidy data set with the average of each variable for each activity and each subject.# tidy data is: (1) each variable forms a column, (2) each observation forms a row, (3) each table/file stores data about one kind of observation. So, we need to have each row = 1 activity and 1 subject and the other variables in column. In other words, activity and subject define the primary key of the table and each pair (subject, activity) identifies an observation. The result is stored in the "dataset_tidy" variable and it contains 1 line for each different pair of subject and activity. subjects and activities are the first 2 columns of the table. The other columns contains the means of the different features for that particular pair (subject, activity).



